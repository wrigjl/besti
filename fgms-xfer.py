#!/us/bin/env python

# @# -*- coding: utf-8 -*-
"""4-23 give to jason.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BPrjBkoQWy1JW8CiTxDBRreYCm6c-qrL
"""



"""### Imports"""

import tensorflow as tf
from tensorflow import keras
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
import pandas as pd
import json
import os
import argparse
from keras import ops
from tensorflow.keras.applications.xception import preprocess_input
import cv2

"""### Global Variables"""

# These are the variables that are global for the program
class_indices = {'disgust': 0, 'fear': 1, 'happiness': 2, 'love': 3, 'sadness': 4, 'surprise': 5, 'violence': 6}

"""### Init Function"""

"""### Img Mod Helper functions"""

#This method is the backbone of all of the examples. It is all that you essentially need to do FGSM for image classifications.
def FGSM(model, input, target, eps=.01):
  input = tf.cast(preprocess_input(input.copy()), tf.float32)
  loss_object = tf.keras.losses.CategoricalCrossentropy()
  with tf.GradientTape() as tape:
    tape.watch(input)
    prediction = model(input)
    loss = -loss_object(target, prediction)
  gradient = tape.gradient(loss, input) #This is probably the most important line of the whole function,
  # as it is what gets the gradients of the inputs and tells us how to generate the noise
  signed_grad = tf.sign(gradient)
  return (signed_grad*eps*255).numpy()

#this function is nessecary because it needs a specific format for the target label
def giveLabel(label, total):
  labelx = tf.one_hot(label,total)
  return tf.reshape(labelx, (1,total))

#This function just uses the other function, and does it multiple times. instead of pushing each input in one big burst, it
#does it by a fraction of the total amount, and then does it again, thereby honing in better on the target.
def FuncStep(func,model,input,target,eps,steps):
  # print(f"input size: {input.shape}")
  temp = np.expand_dims(input.copy(),0)
  print(f"temp size: {temp.shape}")

  for x in range(steps):
    noise = func(model, temp, giveLabel(target,7), eps/steps)
    # print(f"noise size: {noise.shape}")
    temp = np.clip(temp+noise, 0, 255)
  return temp[0]

#This method is the backbone of all of the examples. It is all that you essentially need to do FGSM for image classifications.
def FGMTEST(model, input, target, eps=.01):
  input = tf.cast(preprocess_input(input.copy()), tf.float32)
  loss_object = tf.keras.losses.CategoricalCrossentropy()
  with tf.GradientTape() as tape:
    tape.watch(input)
    prediction = model(input)
    loss = -loss_object(target, prediction)
  gradient = tape.gradient(loss, input) #This is probably the most important line of the whole function,
  # as it is what gets the gradients of the inputs and tells us how to generate the noise
  # signed_grad = tf.sign(gradient)
  # print(f"Thing Type: {type(gradient)}")
  norm_grad = tf.math.l2_normalize(gradient)*300
  return (norm_grad*eps*255).numpy()

#This method is the backbone of all of the examples. It is all that you essentially need to do FGSM for image classifications.
def FGMTEST2(model, input, target, eps=.01):
  input = tf.cast(preprocess_input(input.copy()), tf.float32)
  loss_object = tf.keras.losses.CategoricalCrossentropy()
  with tf.GradientTape() as tape:
    tape.watch(input)
    prediction = model(input)
    loss = -loss_object(target, prediction)
  gradient = tape.gradient(loss, input) #This is probably the most important line of the whole function,
  # as it is what gets the gradients of the inputs and tells us how to generate the noise
  # signed_grad = tf.sign(gradient)
  # norm_grad = tf.math.l2_normalize(gradient)*300
  norm_grad = gradient/tf.reduce_max(tf.math.abs(gradient))*15
  return (norm_grad*eps*255).numpy()

"""### Example of actually using the functions"""


parser = argparse.ArgumentParser(prog='fgsm',
                                 description='fgsm style generator')
parser.add_argument('input_img', help='input image')
parser.add_argument('output_img', help='output image')
parser.add_argument('--method', help='method to output: 1 2 or 3',
                    type=int, default=1)
parser.add_argument('--emotion', default='sadness')
parser.add_argument('--eps', type=float, default=0.7)
parser.add_argument('--steps', type=int, default=4)
parser.add_argument('--model', default="Model12.h5", help="the model file to load")
args = parser.parse_args()


SIZE=260
#input = cv2.resize(cv2.imread(args.input_img), dsize=(SIZE, SIZE),
#                 interpolation=cv2.INTER_CUBIC)

input1 = cv2.imread(args.input_img)
# convert to RGB
rgb = cv2.cvtColor(input1, cv2.COLOR_BGR2RGB)
size = 260
input = cv2.resize(rgb, dsize=(size, size), interpolation=cv2.INTER_CUBIC)

#input = ((image + 1) / 2.0)*255 # This is doing preprocessing on the image based on the -1 to 1 input the training generator was made with
# If the image is 0 to 255 already, then you can just use the image as-is
# Note, I don't do any resizing in the function itself, so if the image isn't already 260x260, you might need to resize it


EPS = args.eps  #amount to disrupt the image by (roughly from 0 to 1)
#LABEL = 1   #any integer from 0 to 6, what label you are perturbing the image towards (see dictionary in global variables)
LABEL = class_indices[args.emotion] # Way to use the dictionary directly
STEPS = args.steps  # number of times to iteratively run the perturbation (best to keep fairly low in single digits)


MODEL = tf.keras.models.load_model(args.model)

if args.method == 1:
  styleimg = FuncStep(FGSM,MODEL,input,LABEL,EPS, STEPS)
elif args.method == 2:
  styleimg = FuncStep(FGMTEST,MODEL,input,LABEL,EPS, STEPS)
elif args.method == 3:
  styleimg = FuncStep(FGMTEST2,MODEL,input,LABEL,EPS, STEPS)

#arr = np.array(styleimg)
# 5) convert RGB â†’ BGR for OpenCV
bgr = cv2.cvtColor(styleimg, cv2.COLOR_RGB2BGR)
# 6) write to disk
success = cv2.imwrite(args.output_img, bgr)

#plt.imsave(args.output_img, styleimg / 255)
